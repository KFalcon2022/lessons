![](../../commonmedia/header.png)

***

   

Многопоточность. java.util.concurrent. Реализации Thread Pool и при чем тут Stream API
======================================================================================

В прошлом уроке мы познакомились с концепцией пула потоков и разобрали интерфейсы, общие для всех реализаций пулов.

Теперь пришло время разобраться с тем, какие реализации пулов существуют в Java.

### ThreadPoolExecutor

Наиболее близкая к канонической реализация, подходящая для большинства задач. Связано это с двумя причинами:

1\. Данный пул не имеет выраженной специфики. Ниже мы познакомимся с более узконаправленными пулами и данный тезис станет понятнее;

2\. У ThreadPoolExecutor достаточно гибкая настройка (как на этапе создания, так и в рамках использования пула), что позволяет сконфигурировать пул на любой вкус, в зависимости от потребностей в рамках конкретной задачи.

Учитывая второй пункт, настройка пула вручную – дело нечастое. Слишком много нюансов, которые нужно учитывать – некоторые параметры связаны между собой. В рамках текущего пункта мы разберем основные настройки, а в конце статьи – познакомимся с классом, который позволяет упростить конфигурацию пулов и предоставляет более простой интерфейс по созданию пулов.

Кроме того, в _ThreadPoolExecutor_ есть ряд публичных методов, которые отсутствуют в _ExecutorService_. Часть из них мы опустим – они являются геттерами/сетерами полей _ThreadPoolExecutor_ или иным образом относятся к конфигурации пула.

Но пару интересных методов мы, все-таки, рассмотрим. После чего познакомимся с основными параметрами конфигурации пула.

#### Методы

Нас интересует лишь два метода, оба связаны с очисткой очереди задач (да, держим в голове, что пул потоков работает на базе блокирующей очереди Runnable’ов (не только их, но не суть)).

1\. **_purge()_**. Данный метод удаляет из очереди задач те, которые были отменены (мы уже упоминали, что механизм Future имеет соответствующую функциональность);

> Безусловно, если этот метод не использовать, обычно ничего страшного не происходит. Просто поток, дошедший до выполнения отмененной задачи, выкинет ее из очереди и перейдет к следующей.  
> Но, как вы можете помнить, классические блокирующие очереди ограничены по размеру. А значит, могут заполниться и попытки добавления задач будут блокировать потоки, пытающиеся это сделать.  
> По сути, мы получим голодание потоков из-за того, что очередь забита задачами, которые уже отменены и не будут выполнены – лишь занимают место.

2\. **_remove(Runnable task)_**. По сути, метод обратный _execute()_. Пытается удалить из очереди _Runnable_, переданный параметром. Может работать некорректно с _submit()_ – там конечный _Runnable_ не всегда является тем, который был передан параметром (тем более, параметром может быть вообще _Callable_). Но в случае с _execute()_ предлагает альтернативу механизму отмены задачи, который для _submit()_ предоставляет _Future_.

Как было сказано выше, остальные методы, специфические для _ThreadPoolExecutor_ направлены на его конфигурацию и/или являются геттерами и сеттерами для его полей. Часть из этих полей рассмотрим в следующем пункте.

#### Поля. И основа конфигурации

Поля предлагаю рассмотреть на базе наиболее «жирного» конструктора данного класса. Именно они позволяют понять, какими параметрами пула можно управлять. И дают общее понимание, какие характеристики пула потоков имеют значение.

· **_int corePoolSize_**. Или базовый размер пула. Это то число потоков, которое будет существовать в пуле, даже если пул не будет иметь задач для всех. У последней формулировки есть две оговорки, но они не критичны в данном контексте.

· **_int maximumPoolSize_**. Максимально допустимо число потоков в пуле. Потоки после превышения _corePoolSize_ могут добавляться, если очередь задач занята – т.е. уже существующие потоки не справляются. При простое (отсутствии задач) эти потоки удаляются.

> В целом, можно сравнить с турбо-частотой у процессора. Если надо, можно разогнать, но на постоянной основе поддерживать избыточно. Если **maximumPoolSize == corePoolSize** – у пула фиксированный размер и он не может расшириться;

· **_long keepAliveTime, TimeUnit unit_**. Период времени, в течении которого будут поддерживаться дополнительные потоки (сверх _corePoolSize_) при отсутствии задач. После истечения заданного периода они будут удалены;

· **_BlockingQueue<Runnable> workQueue_**. Та самая пресловутая очередь задач. При создании экземпляра _ThreadPoolExecutor_ через конструктор мы вынуждены передавать ее явно;

· **_ThreadFactory threadFactory_**. Фабрика потоков. С паттерном «фабрика» и его разновидностях мы еще познакомимся. В контексте данного случая – интерфейс, предлагающий метод, создающий поток. Именно на основе этой штуки будут создаваться потоки-исполнители пула. А значит, благодаря кастомной реализации фабрики можно кастомизировать и конкретные потоки под ваши нужды. Обычно это не требуется, но такая возможность существует;

· **_RejectedExecutionHandler handler_**. Обработчик, который может быть вызван, если пул не может быть расширен (_maximumPoolSize_ достигнут) и очередь потоков заполнена.

> По сути, это механизм, который позволяет избежать блокировки потока при попытке добавить задачу в пул.  
> Есть 4 базовые стратегии (реализации **_RejectedExecutionHandler_**), который предлагает сам пул. Теоретически, можно создать свои реализации и использовать их.  
> Мы не будем рассматривать все 4 стандартные стратегии – их легко найти и ничего сложного в них нет. Лишь отметим, что при стратегии по умолчанию добавление задачи сверх лимита будет приводить к исключению (**RejectedExecutionException**).

Подводя итог, в рамках конфигурации _ThreadPoolExecutor_ мы может влиять на допустимое число потоков в нем, время простоя (до удаления) для дополнительных потоков (для основных – тоже, но через отдельный метод), указывать очередь с задачами для пула и стратегию борьбы с переполнением пула. Кроме того, мы можем задать собственный механизм создания конкретных потоков-исполнителей для заданного пула через реализацию кастомной фабрики потоков.

По сути, описанное позволяет сконфигурировать пул почти под любую задачу, которая может возникнуть.

### ScheduledExecutorService и ScheduledThreadPoolExecutor

В прошлом уроке мы не разобрали один специфический интерфейс-наследник _ExecutorService_ – _ScheduledExecutorService_.

Как можно догадаться из названия, он предлагает механизм для запуска задач по расписанию – как единичных с заданной отсрочкой, так и периодических – с заданным промежутком между срабатываниями.

Область применения данного механизма практически безгранична. Это основа всевозможных таймеров, периодических задач на любой вкус – от строго внутренних, вроде синхронизаций между разными системами/частями системы, до видимых пользователю – скажем, рассылок писем/уведомлений/напоминаний. Наверно, проще перечислить системы, в которых данный механизм не нужен, чем те, в которых необходим.

Интерфейс _ScheduledExecutorService_ имеет всего 3 новых метода (один из них перегружен):

1\. **_schedule()_**. Принимает Runnable (в альтернативной реализации - _Callable_) – задачу, а также параметры для указания периода (число единиц и единицы измерения). Предназначен для назначения единичной задачи на запуск через указанный (параметрами периода) промежуток времени, считая от «сейчас»;

2\. **_scheduleAtFixedRate()_**. Принимает задачу в виде _Runnable_, задержку от «сейчас» до первого исполнения и задержку между исполнениями (запуском предыдущего исполнения и запуском следующего). А также параметр единиц измерения (TimeUnit), относящийся сразу к двум предыдущим параметрам;

3\. **_scheduleWithFixedDelay()_**.Принимает те же параметры, что и предыдущий метод. Но если в _scheduleAtFixedRate()_ задержка означала период между запусками задач, то в данном методе задержка считается от завершения предыдущего запуска до начала следующего. Для задач, выполнение которых происходит не мгновенно, это может иметь значение.

  

Все указанные методы возвращают объект типа _ScheduledFuture_ – наследника знакомого по последним урокам _Future_ и знакомого по блокирующим очередям _Delayed_. Вы же помните _DelayQueue_? Так вот, она здесь не используется:)  
Зато используется похожая на нее непубличная реализация.

В теории, периодические задачи, заданные через один из двух подходящих методов _ScheduledExecutorService_, будут запускаться до бесконечности. На практике же этот процесс может быть прерван через отмену задачи с помощью _Future_ (в данном случае, _ScheduledFuture_). Кроме того, может быть завершена работа самого пула, обслуживающего данную периодическую задачу. И, наконец, завершение одного из запусков с исключением приведет к тому, что задача перестанет запускаться.

Перейдем к реализации интерфейса – _ScheduledThreadPoolExecutor_. Она всего одна и наследует уже разобранный выше _ThreadPoolExecutor_.

В целом, чего-то специфического в ней нет, лишь отметим, что _ScheduledThreadPoolExecutor_ не так гибок в настройке, как его предок. Мы можем указать лишь:

· базовое число потоков (**_corePoolSize_**). Сверх него пул может расширяться до _Integer.MAX\_VALUE_. В контексте пула потоков это, по сути, расширение до бесконечности;

· Фабрику потоков (**_threadFactory_**);

· Стратегия на случай переполнения (**_handler_**). Стратегия по умолчанию не отличается от _ThreadPoolExecutor_ – исключение на добавление в переполненную очередь. Впрочем, с учетом условно-бесконечного пула, переполнение очереди – не самый вероятный сценарий.

Таким образом, с использованием двух изученных реализаций мы имеем пул с гибкой настроек для разовых задач, а также отдельный пул для задач, отложенных во времени или повторяющихся с заданной периодичностью. Что еще может понадобиться Java-разработчику?

### ForkJoinPool

Кроме описанных выше, в Java есть специфический вид пула – _ForkJoinPool_, хорошо подходящий для двух сценариев:

· Простые асинхронные задачи. Которые выполняются быстро и не предполагают блокировки потока внутри пула;

· Асинхронные/параллельные задачи, которые порождают другие асинхронные/параллельные задачи. Отсюда и название: _fork_ – ответвление (вторичной задачи в отдельный поток от текущей) и _join_ – ожидание выполнения такой вторичной задачи в первичной.

Отдельный интересный момент заключается в механизме **work-stealing** – кражи (?) работы. Не погружаясь в детали, освободившийся поток в _ForkJoinPool_ будет пытаться найти себе другую задачу – в т.ч. «забрать» вторичную задачу у другого потока в пуле. Таким образом обеспечивается более равномерная загрузка потоков пула и, тем самым, общая эффективность пула.

> К слову, именно **_ForkJoinPool_** используется для параллельных Stream’ов в Stream API. Механизм «ветвящихся» параллельных задач хорошо ложится в решение параллельной обработки стрима.  
> В таком подходе и, как следствие, в использовании параллельных стримов, есть свои сложности и ограничения, из-за которых не рекомендуется добиваться параллелизма через parallelStream, но для простых операций такой подход имеет право на жизнь.  
>   
> Как бы там ни было, в рамках реальных проектов рекомендую советоваться с более опытными разработчиками при желании использовать параллельные стримы. А так же проверять с помощью логов и других доступных инструментов их эффективность в каждом конкретном случае.  
> Возникающие проблемы могут начинаться от загрузчика классов (для гугла: **ClassLoader java**) до неэффективного определения необходимого уровня параллелизма при выделении пула для конкретного стрима.  
>   
> Возможно, есть и более неприятные вещи, но автор с ними еще не столкнулся:)

Возвращаясь к функциональности _ForkJoinPool_, хочется рассмотреть возможности его конфигурации – они несколько отличаются от того, что есть в _ThreadPoolExecutor_, даже для одинаковых по названиям параметров. Но поскольку мы не слишком глубоко погражаемся в реализацию пула, а полноценная конфигурация _ForkJoinPool_ – крайне редкая задача, остановимся лишь на паре моментов, на которые стоит обратить внимание.

· **_ int parallelism_**. _ForkJoinPool_, в отличии от других пулов потоков, больше ориентирован на то, сколько потоков на самом деле может работать одновременно, а не сколько объектов _Thread_ может лежать в пуле. Поэтому можно задать значение параллелизма явно, если имеется исчерпывающее представление о возможностях процессора и лимитах JVM в среде, где будет использована программа. Или делегировать это самой JVM – документация предлагает использовать _Runtime#availableProcessors()_ для получения информации об уровне параллелизма (условно, число ядер) в рамках среды выполнения;

· **_boolean asyncMode_**. Если задачи пула предполагаются как асинхронные (нужно сделать, но основной поток не блокируется ожиданием результата) и не предполагают активного «ветвления» – данный флаг стоит установить в _true_.

> В таком случае пул будет работать в режиме, который чем-то напоминает fair-доступ у локов и других инструментов – задачи, поступающие в пул будут обрабатываться в порядке поступления в пул.

Значение по умолчанию – _false_. Оно больше подходит для параллельных задач, нежели асинхронных.

Также предлагаю разобрать ключевые методы _ForkJoinPool_, которых нет в уже рассмотренных пулах.

#### static commonPool()

Возвращает _ForkJoinPool_, который система завела по умолчанию. Он имеет некоторые некритичные в работе отличия (читай, оптимизации) относительно _ForkJoinPool_, который мы можем создать руками. И, зачастую, работу с созданием _ForkJoinPool_ стоит ограничить данным методом. Он отлично подходит для не трудоемких задач.

Основная опасность при использовании пула из этого метода – чрезмерное и/или бездумное использование. При заваливании пула трудоемкими задачи могут возникнуть общие проблемы с производительностью системы – могут возникать неожиданные провисания в выполнении за счет того, что задачи ждут своей очереди. А пул, в свое время, занят перевариванием трудоемких задач, которые были переданы в него из другой части системы. Подобные проблемы тяжело идентифицировать и бороться с ними весьма неприятно.

Основная мораль: не грузите _ForkJoinPool.commonPool()_ тяжелыми задачами. Особенно задачами с блокирующими операциями: обращение к внешним ресурсам, включая файлы и БД, длительное ожиданием разделяемого ресурса и т.д. Он для этого не предназначен.

При необходимости выполнять эти операции параллельно или асинхронно стоит использовать другие пулы. В идеале – вообще не _ForkJoinPool_.

  

#### invoke(ForkJoinTask<T> task)

_invoke()_ – метод, который напоминает рассмотренные в предыдущем уроке методы _invokeAll()_ и _invokeAny()_. Его основное отличие в том, что принимает он параметром одну задачу (вместо коллекции), ожидает ее выполнения и возвращает результат.

Второе отличие заключается в том, что мы не работаем с _Callable_.

_Callable_ и _Runnable_ вообще не в чести у _ForkJoinPool_. Как и любой пул, он умеет с ними работать, но предпочитает использование ForkJoinTask.

Строго говоря, _ForkJoinTask_ не является задачей. Этот абстрактный класс – одна из имплементаций _Future_, актуальная для _ForkJoinPool_. Зато он имеет ряд статических методов _adapt()_ по набору параметров идентичных параметрам у различных реализаций _ExecutorService#submit()_.

И как раз _adapt()_\-методы возвращают наследников _ForkJoinTask_, которые также имплементируют _Runnable_ или хранят его в виде поля (с _Callable_ немного хитрее, но суть та же). Так или иначе, объекты этих реализации представляют из себя задачу, имеющую также функциональность, направленную на эффективную обработку в _ForkJoinPool_ – методы

· **_ForkJoinTask#fork()_** – асинхронный запуск задачи, запустивший поток не блокируется;

· **_ForkJoinTask#invoke()_** – синхронный запуск задачи, запустивший поток блокируется до получения результата.

Их рекомендуется использовать для запуска вторичных задач – тех, которые запускаются из задачи, которая уже обрабатывается в ForkJoinPool’е. Это предпочтительнее, чем использовать в таких случаях методы самого _ForkJoinPool_.

Данная концепция немного громоздка, особенно на первый взгляд, но относительно проста в использовании.

#### execute(ForkJoinTask<?> task)

Здесь ничего особенного. Принимает параметром таск, который необходимо выполнить в рамках пула. Является перегрузкой _Executor#execute(Runnable runnable)_, только в качестве параметра принимает более близкий данному пулу _ForkJoinTask_.

#### submit(ForkJoinTask<T> task)

Еще одна перегрузка. Как _ExecutorService#submit()_ но с поправкой на реалии _ForkJoinPool_.

  

Отдельно стоит отметить, что методы _submit()_ (как новый, так и известные по _ExecutorService_) в _ForkJoinPool_ возвращают не просто _Future_, а _ForkJoinTask_, который имеет расширенную функциональность, в сравнении со своим предком.

Кроме рассмотренных методов, есть еще несколько, обеспечивающих вспомогательные функции при необходимости более тонкой работы с пулом. Их мы не будем рассматривать в силу узости их сферы применения. Боюсь, в контексте необходимости осознать связку _ForkJoinPool_ – _ForkJoinTask_ данный урок и так получился нагруженным. Для тех, кому действительно интересно разобраться – рекомендую больше внимания уделить практике и документации/исходному коду. Ничего сложного здесь нет, но нужно потратить время на осознание концепции.

### Утилитный класс Executors

Мы рассмотрели все основные реализации thread pool’ов в _java.util.concurrent_ – их всего три.

Но, как и во многих других случаях, для сложных/гибких механик Java предлагает вспомогательный класс со статическими методами. В данном случае – _Executors_.

Он предлагает несколько методов по превращению _Runnable_ (и не только) в _Callable_ – см. _callable()_, метод с дефолтной реализацией фабрики потоков – _defaultThreadFactory()_ и, самое главное – 14 методов для создания пулов потоков.

Чтобы не разбирать каждый метод по отдельности, отметим категории пулов, которые он предлагает:

· **_С фиксированным числом потоков_**. _corePoolSize == maximumPoolSize_;

· **_С использованием work-stealing механизма_**. Читай, сконфигуренные ForkJoinPool’ы;

· Однопоточные пулы – _corePoolSize == maximumPoolSize == 1_;

· **_Кэшированные пулы_**. _corePoolSize == 0_, но _maximumPoolSize_ не ограничен. При появлении задач создаются потоки, когда задачи заканчиваются – живут в течении минуты (находятся в «кэше») и завершаются, если не дождутся новых задач. При поступлении новых задач после завершения кэшированных потоков – создаются новые;

· **_Scheduled-пулы_**. Однопоточные и нет;

· **_«Не сконфигуренные» пулы_**. Возвращают обертку над реализациями _ExecutorService_/_ScheduledExecutorService_ (в зависимости от метода), которые принимают параметром. Все операции, доступные данным интерфейсам, делегируют пулу, который был передан параметром.

> Удобны тем, что гарантируют недоступность кастомных методов пула даже при желании пользователя – используется объект-обертка, что исключает возможность обращения к кастомным методам через downcast.  
>   
> Так, например, с помощью подобных методов можно **ForkJoinPool** ограничить в функциональности до **ExecutorService**. Главное понять, зачем это нужно:)

### В качестве заключения

Пулы потоков – очень полезная тема при практическом использовании многопоточности. Независимо от остальных тем данного раздела, крайне рекомендую разобраться в ней хотя бы на том уровне, который предлагает данный урок.

В целом, в ней нет ничего сложного, если мы говорим об использовании пулов, а не их внутреннем устройстве. Даже _ForkJoinPool_ достаточно прост, если потратит ьна него немного времени. Остальные пулы еще более прозрачны.

Надеюсь, данная статья поможет вам в осознании возможностей данных механик.

С теорией на сегодня все!

![](../../commonmedia/footer.png)

Переходим к практике:

### Задача 1

Реализуйте программу, которая выводит актуальное время каждую минуту, начиная с текущего момента. Не используйте _Thread.sleep()_ или циклы.

### Задача 2

Реализуйте программу, которая сообщает о начале каждого часа. Не используйте _Thread.sleep()_ или циклы.

_Примечание_: для _Задач 1_ и _2_ в рамках отладки можно выбрать любые промежутки времени. Скажем, не каждую минуту, а каждую секунду. Или не «начало каждого часа», а «начало каждой минуты». Концептуально это не влияет на решение.

### Задача 3

Реализуйте третий вариант [Задачи 2 урока 60](/Mnogopotochnost-Klass-Thread-Sposoby-sozdaniya-potoka-03-25#%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0-2) с использованием пулов потоков.

### Задача 4

Реализуйте программу, которая выводит числа от 0 до 100 в консоль. Выведения каждого десятка должно быть вынесено в отдельный поток, в котором будут запущены потоки на выведение каждого конкретного числа.

Каждый конечный поток обязан спать в течении 500мс после того, как выведет число в консоль.

  

Если что-то непонятно или не получается – welcome в комменты к посту или в лс:)

Канал: [https://t.me/ViamSupervadetVadens](https://t.me/ViamSupervadetVadens)

Мой тг: [https://t.me/ironicMotherfucker](https://t.me/ironicMotherfucker)

_Дорогу осилит идущий!_