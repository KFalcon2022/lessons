![](../../commonmedia/header.png)

***

   

Многопоточность. Проблемы многопоточности
=========================================

Сегодня мы разберем основные проблемы многопоточности – стандартные ошибки, возникающие в многопоточной среде в силу неправильного проектирования системы в части синхронизации взаимодействия потоков. Постараемся понять, как отследить такие сценарии и как с ними бороться.

В целом, мы уже встречались с большинством из них как в теории, так и в рамках практических задач. Однако именно сегодня мы разберем их более подробно.

Сразу стоит отметить, что основная сложность при борьбе с рассматриваемыми проблемами – их идентификация и локализация. Потому что привычные средства, такие как дебагер, не позволяют отлавливать такие ситуации – точки останова влияют на порядок взаимодействия потоков, что приводит к тому, что отловить ошибку не удается.

Вторая сложность, в целом, возникает из первой. Поскольку проблемы многопоточности связаны с взаимодействием нескольких потоков, в большинстве случаев возникающие ошибки поведения (баги) являются «плавающими» – нет гарантии, что они будут воспроизводиться каждый раз, поскольку планировщик потоков не гарантирует порядка запуска потоков, а значит и однообразности их взаимодействия. Т.е. даже воспроизведение ошибки в «домашних» условиях, не говоря о ее локализации, может быть целым приключением.

Теперь перейдем к рассмотрению конкретных проблем.

### Deadlock

**Deadlock** (дедлок, взаимная блокировка) – сценарий, в котором несколько потоков ожидают ресурсы, заблокированные друг другом. В итоге ни один из них не может получить доступ к нужному ресурсу и не может продолжать выполнение, в т.ч. и разблокировать уже занятый ресурс. Результат – потоки заблокированы без шанса вернуться к выполнению задачи.

Разберем на простом примере:

```java
var res1 = "1";
var res2 = "2";

Runnable task1 = () -> {
  synchronized (res1) {
    Thread.sleep(1000); // try-catch проигнорирован для лакончичности

    synchronized (res2) {
      System.out.printf("res1: %s; res2: %s\n", res1, res2);
    }
  }
};

Runnable task2 = () -> {
  synchronized (res2) {
    Thread.sleep(1000); // try-catch проигнорирован для лакончичности

    synchronized (res1) {
      System.out.printf("res2: %s; res1: %s\n", res2, res1);
    }
  }
};

new Thread(task1).start();
new Thread(task2).start();
```

Допустим нас есть два разделяемых ресурса: _res1_ и _res2_.

Первый поток пытается захватить монитор _res1_ (успешно), а затем – монитор _res2_.

Второй поток пытается захватить монитор _res2_ (успешно), а затем – монитор _res1_.

В итоге получается, что первый поток не может захватить _res2_, потому что его монитор занят вторым потоком, а второй поток не может захватить _res1_ – он занят первым потоком. При этом освободить захваченные ресурсы потоки не могут – первая критическая секция не может быть завершена, пока не отработала вторая (вложенная) критическая секция.

Может показаться непонятным, зачем вообще блокировать один ресурс внутри другого. Предлагаю обратиться к более приближенному к реальной жизни (и задачам) примеру: нам нужно перевести деньги с одного банковского счета на другой.

Алгоритм прост – нужно взять счет-отправитель (_Счет1_), вычесть из его баланса сумму перевода, а после зачислить эту сумму на счет-получатель (_Счет2_).

Но проблема в том, что в этом время могут происходить и другие операции со счетами, т.е. нам нужно синхронизировать списание и зачисление денег на счет. Наиболее простое решение, которое приходит в голову – получить монитор счета-отправителя (_Счет1_), после получить монитор счета-получателя (_Счет2_) и уже после этого, имея гарантию неизменности состояния двух счетов провести нужный нам денежный перевод.

Собственно, именно такое решение синхронизации двух объектов и приведено выше (любой из _Runnable_). Если в это же время будет попытка перевода наоборот – со _Счета2_ на _Счет1_ – возникнет взаимная блокировка – для каждого из перевода монитор счета-получателя будет заблокирован потоком, где этот счет считается отправителем.

К сожалению, далеко не всегда deadlock настолько очевиден – иногда он возникает в разных блоках синхронизации на одни и те же ресурсы. Иногда в нем участвуют больше двух потоков и двух ресурсов (задача об обедающих философах, рассматриваемая несколько уроков назад – один из примеров). Так или иначе, причину возникновения дедлока иногда приходится искать.

Дебаг здесь не поможет – пока мы будем находиться к точках останова, другие потоки могут завершить свое выполнение, в итоге все пройдет штатно и ситуация не воспроизведется.

Но нам может помочь другой инструмент, позволяющий узнать состояние всех потоков в системе к заданный момент времени – **Thread dump** (дамп потоков). Он представляет собой файл, в котором описаны статусы существующих потоков, а также стектрейс с указанием строчки кода, в которых эти потоки находились (выполнялись или ожидали) в момент создания дампа. Таким образом, мы можем идентифицировать, в каких местах «зависли» конкретные потоки. Обычно, этого достаточно, чтобы локализовать проблему.

Решать взаимную блокировку можно по-разному. Мы рассмотрим наиболее общий подход. Он заключается в вводе правила получения блокировок. Скажем, в случае с банковскими счетами мы можем опереться на идентификатор счета. И ввести правило, при котором поток всегда захватывает монитор счета с большим идентификатором, а затем – с меньшим. В таком случае, алгоритм будет опираться не на относительное определение ресурса (отправитель/получатель), а на абсолютное – вне зависимости от роли, идентификатор счета неизменен.

Если рассматривать на примере, описанном в виде кода – такое подход гарантирует, что любой поток сначала попытается захватить _res2_, а только потом – _res1_. Получится, что взаимная блокировка не случится – второй поток не зайдет в критическую секцию (_res1_ уже занят), пока первый поток ее не покинет.

Логическое продолжение этой идеи (не совсем очевидное) заключается в том, что если поток уже владеет ресурсом, но ему понадобился ресурс с б**_о_**льшим идентификатором – поток обязан сначала освободить уже заблокированный ресурс, получить контроль над ресурсом с б**_о_**льшим идентификатором, а лишь затем снова заблокировать ресурс, которым владел изначально. Да, это дополнительные операции и в моменте они могут быть избыточны – например, ресурсы и так никто не претендовал – но они дают гарантию, что deadlock не возникнет, при этом схема решение (и кодовая база) остается достаточно прозрачной.

Дедлок, вероятно, наиболее известная проблема многопоточности. Благо, она, наверно, и самая простая в плане локализации и решения.

В заключение отметим, что возникновение блокировки не обязательно связано с _synchronized_\-блоком. С тем же успехом на его месте могут быть локи или еще какие-то формы синхронизации, так или иначе сводящиеся к тому, что одна критическая секция находится внутри другой.

### Livelock

**Livelock** (динамическая блокировка) – проблема, при которой потоки не заблокированы в явном виде, но заняты циклическим переключением между состояниями, а не полезной работой.

Теоретически, может стать результатом некорректного решения deadlock’а.

Стоит отметить, что это менее распространенная проблема, чем остальные, рассматриваемые в статье. Поэтому ей обычно уделяют мало внимания при изучении проблем многопоточности.

Контекст тот же, что и в предыдущем примере – первый поток пытается захватить _res1_, а затем – _res2_. Второй поток – наоборот. Но чтобы не возникало взаимной блокировки, мы выработали следующий алгоритм: если ресурс, который поток пытается получить вторым, уже занят – поток должен освободить первый ресурс, потом захватить второй и лишь затем – снова попытаться захватить первый.

В результате может сложиться ситуация, когда потоки попеременно захватывают _res1_ и _res2_, но не могут приступить к выполнению полезной работы потому что _res2_ и _res1_ соответственно захвачены потоком конкурентом. В итоге потоки заняты циклическим переключением между ресурсами, но оба ресурса не получает ни один из потоков.

Обнаружить ситуацию достаточно легко при наличии логов – записей о действиях потоков. В нашем случае, каждый из потоков будет писать в логи примерно следующее:

```java
res1 захвачен
res2 заблокирован, освобожден res1

res2 захвачен 
res1 заблокирован, освобожден res2

res1 захвачен
res2 заблокирован, освобожден res1

res2 захвачен 
…
```

Решение то же, что и при дедлоке – прозрачная стратегия захвата ресурсов на базе иерархии самих ресурсов.

### Thread starvation

**Thread starvation** (голодание потока) – проблема, в общем случае сводящаяся к тому, что поток не заблокирован, но все равно не выполняется, потому что ему не выделяется процессорное время.

Данный сценарий обычно связан с использованием явной приоритизации потоков. В целом, на уровне операционной системы обычно существуют механизмы противостояния этой проблеме – в т.ч. явное выделение процессорного времени потокам с низким приоритетом. Но правильнее избегать причин данной проблемы, нежели работать с ее последствиями.

Так, программист имеет простой способ противостояния голоданию потоков: отказ от использования приоритетов или сведение использований данного механизма к минимуму. Если все (или абсолютное большинство) потоков имеют равный приоритет – проблема перестает быть актуальной.

Также под голоданием потоков иногда подразумевают ситуации, когда поток долго не получает доступа к ресурсу – в меньшем степени из-за длительной блокировки ресурса другим потоком, чаще в контексте того, что доступ к ресурсу получают разные потоки, но до конкретного голодающего очередь не доходит. В том числе из-за отсутствия очереди.

> В данном случае можно также встретить формулировки вроде «**голодание чтения**» (**read-starvation**, **reader-starvation**) или «**голодание записи**» (**write-starvation**, **writer-starvation**). Это частный случай подобного голодания, актуальный, например, для некоторых реализаций **ReadWriteLock**.  
> Пример не относится к **ReentrantReadWriteLock** в **java.util.concurrent**, но может быть актуально для сторонних реализаций, где операции чтения или записи имеют приоритет относительно друг друга.  
>   
> Это не слишком относится к основной теме, зато полезно для кругозора:)  

Проблему голодания в контексте «не предоставления» доступа к ресурсу можно решать по-разному, в зависимости от контекста конкретной задачи.

Первый вариант – решение в лоб. Использование механизмов справедливого предоставления доступа. По сути, гарантия того, что потоки получают доступ в порядке очереди, а не по велению левой пятки планировщика, приоритетов потоков или других причин. Его очевидные минусы – падение производительности и отсутствие данного механизма у ряда инструментов синхронизации. Для последнего случае могут вводиться дополнительные критические секции, основной целью которых будет обеспечение fair-доступа.

Второй вариант заключается в избавлении от первоисточника голодания. Например, если удастся выяснить, что высокая конкуренция за ресурс связана не с общей нагрузкой на систему, а отсутствием грамотной синхронизации в другом месте или с неудачным выбором инструмента синхронизации, или с какими-то иными нюансами, вплоть до сценариев использования, которые гарантируют, что ряд операций, приводящих к повышенной конкуренции за ресурс, избыточен.

Так или иначе, данный подход связан с тем, что текущий уровень конкуренции является результатом ошибки. И лечить нужно не голодание, а первопричину «популярности» ресурса. Данный подход применим, безусловно, не всегда – в конце концов, иногда ресурс «популярен» просто потому что система высоконагруженная и в ней большинство ресурсов «популярны». Но даже тогда, когда источником действительно является ошибка проектирования – нужно глубокое понимание системы и опыт, чтобы идентифицировать подобную проблему и решить ее.

В целом, данный подход не является чем-то специфическим для решения проблемы голодания потока или решения проблем многопоточности в целом – он применим безотносительно конечной ошибки и ее природы. Но о нем необходимо вспоминать время от времени. В случае же проблем многопоточности – это вдвойне актуально, потому что наиболее тяжелые (в исправлении) из ошибок, связанных с многопотоностью, зачастую вызваны именно ошибками проектирования.

### Race condition

**Race condition** (гонка потоков) – вероятно, наиболее распространенная из проблем многопоточности. По сути, объединяет все сценарии, при которых взаимодействие потоков не было реализовано достаточно корректно, из-за чего поведение программы отличается от ожидаемого или просто является непредсказуемым.

Проблематика простирается от потерянного блока _synchronized_ или лока, продолжается пренебрежением атомарностью операций и заканчивается отсутствием синхронизации разделяемого ресурса в разных частях программы. На самом деле, не заканчивается. Проблема гонки потоков практически безгранична в своем многообразии, но заключается именно в недостаточной регуляции взаимодействия потоков.

Простейшим (и очень узким) примером можно считать добавление элемента в мапу, если он отсутствует.

Допустим, у нас есть потокобезопасная мапа и мы хотим добавить туда элемент, если по такому ключу элемента нет:

```java
var map = ...; //какая-то ConcurrentHashMap

if (!map.containsKey("1")) { //такого ключа в данный момент нет

// Примерно в этот момент другой поток добавил объект по ключу "1" 

map.put("1", new Object()); // мы добавляем свой объект, но на самом 
                            // деле объект с таким ключом уже был
}
```

В данном случае проблема в том, что атомарными являются действия проверки наличия ключа и вставка элемента по ключу. А вот совокупность этих действий уже не атомарна, между ними другой поток может успеть вставить элемент.

Решение здесь тривиальное: использовать _putIfAbsent()_, который у _ConcurrentHashMap_ гарантирует атомарность.

Другим примером может послужить счетчик, значение которого изменяется разными потоками. Если операция обращения к счетчику не синхронизирована, а счетчик не представлен atomic-типом – изменение его значений может происходить не так, как ожидается – в т.ч. с потерей части обновлений из-за «перетирания» – на момент обновления один поток не отследил обновление другого потока. Решение задано в условии – использование atomic-типов или механизмов синхронизации при доступе к разделяемому ресурсу (счетчику).

К сожалению, в других ситуациях решения бывают не так очевидны, как и сами проблемы. Усугубляется все тем, что воспроизводимость гонки потоков может быть еще ниже, чем у deadlock’а. И дебаг тут так же не сможет помочь. Впрочем, thread dump тоже, чаще всего, будет бесполезен.

Как и в случае с livelock, проблему проще всего отследить через логи, если она возникла. Чаще всего самих логов недостаточно, но они помогают локализовать проблему до конкретных методов или цепочек вызовов. Дальнейший поиск причин зачастую сводится к изучению конкретных блоков кода разработчиком в поиске мест, где отсутствует требуемая синхронизация и/или отсутствует гарантия атомарности операций.

Данный процесс может быть крайне трудоемким и требовать глубокого понимания многопоточности, что делает race condition самой неприятной из рассмотренных проблем.

  

### В качестве вывода

Мы разобрали основные проблемы многопоточности. Но помните, что у любой проблемы в реальном проекте есть свой контекст. И решение этих проблем должно учитывать данный контекст.

К сожалению, часто сложность решения связана именно с особенностями реализации конкретных пользовательских функций. И решить проблему, не сломав логику и не переписывая полпроекта, – искусство.

Хорошая новость заключается в том, что подобные задачи крайне увлекательны и часто позволяют глубже нырнуть в специфику проекта. В общем, дорога тяжела, но ее осилит идущий:)

  

С теорией на сегодня все!

Урок ознакомительный, поэтому практики не будет.

![](../../commonmedia/footer.png)

Если что-то непонятно или не получается – welcome в комменты к посту или в лс:)

Канал: [https://t.me/ViamSupervadetVadens](https://t.me/ViamSupervadetVadens)

Мой тг: [https://t.me/ironicMotherfucker](https://t.me/ironicMotherfucker)

_Дорогу осилит идущий!_